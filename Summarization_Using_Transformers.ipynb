{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1rlVP4u4M8Zt65UVktMd38grWcCkC0Z9S","authorship_tag":"ABX9TyP8Plnn5ZC3ESILCxqe5pjd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ebfd5ce61c994aaca1b97bc9aaab3715":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_247cd0120737437bbca487eed099abfd","IPY_MODEL_0427acc3208c4469a0593567c7954a6b","IPY_MODEL_4b4f5f7757ae412984c1c54185c4f9b4"],"layout":"IPY_MODEL_cb6d3395334249b4a433605c41932458"}},"247cd0120737437bbca487eed099abfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1e825ba38b94e3083b27334480e1101","placeholder":"â€‹","style":"IPY_MODEL_e5c8466293d7493d839694605121b8a0","value":"Map:â€‡100%"}},"0427acc3208c4469a0593567c7954a6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1eb79be7abd84d2eac3f543c8292a60a","max":14732,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d19f037f95bd4200ae4d7a2840a44b45","value":14732}},"4b4f5f7757ae412984c1c54185c4f9b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62a15031d318479c9271c39e41afa642","placeholder":"â€‹","style":"IPY_MODEL_ef97c4d41c5349e8b7d7682d08c674c3","value":"â€‡14732/14732â€‡[00:13&lt;00:00,â€‡1275.20â€‡examples/s]"}},"cb6d3395334249b4a433605c41932458":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1e825ba38b94e3083b27334480e1101":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5c8466293d7493d839694605121b8a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1eb79be7abd84d2eac3f543c8292a60a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d19f037f95bd4200ae4d7a2840a44b45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62a15031d318479c9271c39e41afa642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef97c4d41c5349e8b7d7682d08c674c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38a59841a3e548b8b56d94e7d31e5885":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25dd78ad6d97412696c870faa3d8e8f3","IPY_MODEL_4cb73342e1704f97a3f69f9643389328","IPY_MODEL_c9215a0503ab44aba082243004d4a8a1"],"layout":"IPY_MODEL_04c30feb23ce40b2b2911b9b6d831368"}},"25dd78ad6d97412696c870faa3d8e8f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74073fada0da4004abd5f5eff598d484","placeholder":"â€‹","style":"IPY_MODEL_233e53504ab9462ba37ba115e5a2e243","value":"Map:â€‡100%"}},"4cb73342e1704f97a3f69f9643389328":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bf0c169703446a8b3ec107080ea9517","max":819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e143c95a89514b80831f7e8ce7e24371","value":819}},"c9215a0503ab44aba082243004d4a8a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5deba76df330493487639d7eaeb30591","placeholder":"â€‹","style":"IPY_MODEL_c26acb4c2e754a95bb7a8dd4e8cf4c3d","value":"â€‡819/819â€‡[00:00&lt;00:00,â€‡1257.86â€‡examples/s]"}},"04c30feb23ce40b2b2911b9b6d831368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74073fada0da4004abd5f5eff598d484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"233e53504ab9462ba37ba115e5a2e243":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bf0c169703446a8b3ec107080ea9517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e143c95a89514b80831f7e8ce7e24371":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5deba76df330493487639d7eaeb30591":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c26acb4c2e754a95bb7a8dd4e8cf4c3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c56d27e5be846deaabaf6a95e1d7929":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73f29e457a1a4bb5b1e85c670ca5f6b0","IPY_MODEL_77ba88d0963f4381926a683e0b601f42","IPY_MODEL_7407436326424669b3804302f918e739"],"layout":"IPY_MODEL_84bac9b8d9c1413cbaa89b672782da3a"}},"73f29e457a1a4bb5b1e85c670ca5f6b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fface83d2d44595aefda99fe59810b4","placeholder":"â€‹","style":"IPY_MODEL_d49b0e3eab834dde975170b43aea67c0","value":"Map:â€‡100%"}},"77ba88d0963f4381926a683e0b601f42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf4e2c7523aa43a3bcdfd4dc01d53adb","max":818,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1cd103ae3944acfa8c4b45166416bca","value":818}},"7407436326424669b3804302f918e739":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf54c726d7be4a99b3084b0de62650bb","placeholder":"â€‹","style":"IPY_MODEL_21066ef183a4428a9fa71af4be9056d5","value":"â€‡818/818â€‡[00:00&lt;00:00,â€‡913.29â€‡examples/s]"}},"84bac9b8d9c1413cbaa89b672782da3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fface83d2d44595aefda99fe59810b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d49b0e3eab834dde975170b43aea67c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf4e2c7523aa43a3bcdfd4dc01d53adb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1cd103ae3944acfa8c4b45166416bca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf54c726d7be4a99b3084b0de62650bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21066ef183a4428a9fa71af4be9056d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"25fKQ-KgjJHa","executionInfo":{"status":"ok","timestamp":1745648436207,"user_tz":-345,"elapsed":2936,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"outputs":[],"source":["# Installs Hugging Face Transformers with SentencePiece (for models like T5),\n","#  Datasets (for easy dataset access), sacrebleu & rouge_score (evaluation metrics),\n","# and py7zr (for handling .7z files), all in quiet mode\n","!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"]},{"cell_type":"code","source":[],"metadata":{"id":"ae728qxft20_","executionInfo":{"status":"ok","timestamp":1745648436221,"user_tz":-345,"elapsed":2,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install evaluate -q"],"metadata":{"id":"fAt-k9vtnHgT","executionInfo":{"status":"ok","timestamp":1745648441592,"user_tz":-345,"elapsed":5370,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nf9uxjktj-fK","executionInfo":{"status":"ok","timestamp":1745648441690,"user_tz":-345,"elapsed":99,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"0e698055-1e0a-472d-a1fa-dbadabe4d7d1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Apr 26 06:21:32 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!pip show datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90nnEtcplvkZ","executionInfo":{"status":"ok","timestamp":1745648443514,"user_tz":-345,"elapsed":1823,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"73691737-2f4e-4a71-ff05-c09931cd1b77"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: datasets\n","Version: 3.5.0\n","Summary: HuggingFace community-driven open-source library of datasets\n","Home-page: https://github.com/huggingface/datasets\n","Author: HuggingFace Inc.\n","Author-email: thomas@huggingface.co\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, tqdm, xxhash\n","Required-by: evaluate\n"]}]},{"cell_type":"code","source":["# Import libraries\n","from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n","from datasets import load_dataset\n","from evaluate import load as load_metric  # âœ… Updated version of load_metric\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","from tqdm import tqdm\n","import torch\n","\n","# Download required tokenizer data\n","nltk.download(\"punkt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Na_xdWVKlzrA","executionInfo":{"status":"ok","timestamp":1745648461996,"user_tz":-345,"elapsed":18480,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"977ee6da-76bd-48d5-a65e-e0d93382b86b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Checks if a CUDA-compatible GPU is available and sets the device accordingly.\n","# If GPU is available, set device to \"cuda\", else fallback to \"cpu\".\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"yeDeUlyqlzug","executionInfo":{"status":"ok","timestamp":1745648462121,"user_tz":-345,"elapsed":118,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"14742555-dcfc-44ae-9e6f-75c4e171a902"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Specify the pre-trained model checkpoint (Pegasus model fine-tuned on CNN/DailyMail dataset for summarization)\n","model_ckpt = \"google/pegasus-cnn_dailymail\"\n","\n","# Load the tokenizer associated with the specified model checkpoint. This tokenizer will convert text into token IDs\n","# that the model can understand, and will also decode model outputs back into human-readable text.\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nchgADu8oZh5","executionInfo":{"status":"ok","timestamp":1745648465189,"user_tz":-345,"elapsed":3060,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"fefaf596-8c99-4e17-ff5a-ea3bf707d8f7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Load the pre-trained model (Pegasus model for sequence-to-sequence tasks such as summarization)\n","# .to(device) sends the model to the selected device (GPU if available, otherwise CPU)\n","model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74jOTnHvov7X","executionInfo":{"status":"ok","timestamp":1745648479955,"user_tz":-345,"elapsed":14764,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"2bdd3c25-552e-41d6-caa5-f65b880327b4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Load data\n","dataset_samsung = load_dataset(\"samsum\")\n","dataset_samsung"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHUcICm8paM7","executionInfo":{"status":"ok","timestamp":1745648481481,"user_tz":-345,"elapsed":1525,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"1ad2a94b-b42b-4965-af13-041812139b67"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 14732\n","    })\n","    test: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 819\n","    })\n","    validation: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 818\n","    })\n","})"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["split_lengths = [len(dataset_samsung[split]) for split in dataset_samsung]\n","split_lengths"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sY-A0bXyqQxG","executionInfo":{"status":"ok","timestamp":1745648481498,"user_tz":-345,"elapsed":16,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"03ec0e9b-0a4e-484b-9937-ecb57682b884"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[14732, 819, 818]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["print(f\"Features: {dataset_samsung['train'].column_names}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0oMhbvwrG1u","executionInfo":{"status":"ok","timestamp":1745648481519,"user_tz":-345,"elapsed":14,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"11bb9b2b-6076-4bb4-d9ad-f33c1e627134"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: ['id', 'dialogue', 'summary']\n"]}]},{"cell_type":"code","source":["# Printing dialogue at index 1 from the dataset\n","print(\"\\nDialogue:\")\n","print(dataset_samsung[\"test\"][1][\"dialogue\"])\n","\n","print(\"\\nSummary:\")\n","print(dataset_samsung[\"test\"][1][\"summary\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftiKAFebrN__","executionInfo":{"status":"ok","timestamp":1745648481531,"user_tz":-345,"elapsed":11,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"387aa752-967d-431f-9b5c-1a9c799e53c0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Dialogue:\n","Eric: MACHINE!\r\n","Rob: That's so gr8!\r\n","Eric: I know! And shows how Americans see Russian ;)\r\n","Rob: And it's really funny!\r\n","Eric: I know! I especially like the train part!\r\n","Rob: Hahaha! No one talks to the machine like that!\r\n","Eric: Is this his only stand-up?\r\n","Rob: Idk. I'll check.\r\n","Eric: Sure.\r\n","Rob: Turns out no! There are some of his stand-ups on youtube.\r\n","Eric: Gr8! I'll watch them now!\r\n","Rob: Me too!\r\n","Eric: MACHINE!\r\n","Rob: MACHINE!\r\n","Eric: TTYL?\r\n","Rob: Sure :)\n","\n","Summary:\n","Eric and Rob are going to watch a stand-up on youtube.\n"]}]},{"cell_type":"code","source":["# Evaluating PEGASUS in samsum\n","dataset_samsung['test'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YcBwxOS3rTH0","executionInfo":{"status":"ok","timestamp":1745648481561,"user_tz":-345,"elapsed":30,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"b2a97c54-3347-4c0a-a2fc-1e25c765b8b4"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '13862856',\n"," 'dialogue': \"Hannah: Hey, do you have Betty's number?\\nAmanda: Lemme check\\nHannah: <file_gif>\\nAmanda: Sorry, can't find it.\\nAmanda: Ask Larry\\nAmanda: He called her last time we were at the park together\\nHannah: I don't know him well\\nHannah: <file_gif>\\nAmanda: Don't be shy, he's very nice\\nHannah: If you say so..\\nHannah: I'd rather you texted him\\nAmanda: Just text him ðŸ™‚\\nHannah: Urgh.. Alright\\nHannah: Bye\\nAmanda: Bye bye\",\n"," 'summary': \"Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\"}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# I checked the model performance, if it is doing good, no need to fine tuning as tunign can be costly\n","# If the model is not doing good, then only do fine tuning"],"metadata":{"id":"FxAClNlLrrde","executionInfo":{"status":"ok","timestamp":1745648481578,"user_tz":-345,"elapsed":16,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["dialogue = dataset_samsung['test'][0]['dialogue']\n","dialogue"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"7fR_V0sMsHt5","executionInfo":{"status":"ok","timestamp":1745648481589,"user_tz":-345,"elapsed":10,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"e8ed434a-8263-489e-b257-d6115f090f43"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Hannah: Hey, do you have Betty's number?\\nAmanda: Lemme check\\nHannah: <file_gif>\\nAmanda: Sorry, can't find it.\\nAmanda: Ask Larry\\nAmanda: He called her last time we were at the park together\\nHannah: I don't know him well\\nHannah: <file_gif>\\nAmanda: Don't be shy, he's very nice\\nHannah: If you say so..\\nHannah: I'd rather you texted him\\nAmanda: Just text him ðŸ™‚\\nHannah: Urgh.. Alright\\nHannah: Bye\\nAmanda: Bye bye\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Create a summarization pipeline using the loaded Pegasus model.\n","# This pipeline handles tokenization, model inference, and decoding in one step,\n","# allowing you to easily generate summaries from input text.\n","pipe = pipeline(\"summarization\", model=model_pegasus, tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zkupy9ausLR8","executionInfo":{"status":"ok","timestamp":1745648481606,"user_tz":-345,"elapsed":16,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"6da5da54-3c48-4933-c113-bb3ce699a8e9"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}]},{"cell_type":"code","source":["pipe_out = pipe(dialogue)\n","pipe_out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iTEXJgKsW2g","executionInfo":{"status":"ok","timestamp":1745648483726,"user_tz":-345,"elapsed":2119,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"98e13cbb-a45d-4f3e-9bea-647d0bd96aba"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'summary_text': \"Amanda: Ask Larry Amanda: He called her last time we were at the park together .<n>Hannah: I'd rather you texted him .<n>Amanda: Just text him .\"}]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# For better displaying of summary\n","print(pipe_out[0]['summary_text'].replace(\" .<n>\", \".\\n\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDJOii54sjvR","executionInfo":{"status":"ok","timestamp":1745648483748,"user_tz":-345,"elapsed":14,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"7563f5e4-6f65-47b7-d092-2946c0d31fbe"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Amanda: Ask Larry Amanda: He called her last time we were at the park together.\n","Hannah: I'd rather you texted him.\n","Amanda: Just text him .\n"]}]},{"cell_type":"code","source":["# Since while training this model, they have not used samsum dataset, so i need to do fine tuning for better summary generation\n","# I fine tuned using samsum data"],"metadata":{"id":"WBZid2-BsxVb","executionInfo":{"status":"ok","timestamp":1745648483758,"user_tz":-345,"elapsed":9,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def generate_batch_sized_chunks(list_of_elements, batch_size):\n","    \"\"\"\n","    Splits a large list into smaller batches of a specified size.\n","\n","    This is useful for processing long lists of text (e.g., articles or documents)\n","    in manageable chunks, especially when passing data to models that have input length\n","    or memory constraints (like Pegasus). It also improves performance by enabling\n","    batch processing instead of looping through items one by one.\n","\n","    Yields:\n","        Slices (chunks) of the original list, each of length 'batch_size' (except the last one, which may be smaller).\n","    \"\"\"\n","    for i in range(0, len(list_of_elements), batch_size):\n","        yield list_of_elements[i : i + batch_size]\n"],"metadata":{"id":"nBflJ6cNtWQs","executionInfo":{"status":"ok","timestamp":1745648483767,"user_tz":-345,"elapsed":8,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n","                                batch_size=16, device=device,\n","                                column_text=\"article\", column_summary=\"highlights\"):\n","    \"\"\"\n","    Calculates the evaluation metric (like ROUGE) on a test dataset.\n","\n","    Args:\n","        dataset: The dataset split (e.g., dataset[\"test\"])\n","        metric: The metric object (like ROUGE)\n","        model: The summarization model\n","        tokenizer: Tokenizer corresponding to the model\n","        batch_size: Number of samples to process at once\n","        column_text: The name of the column containing the input text\n","        column_summary: The name of the column containing the reference summaries\n","\n","    Returns:\n","        The computed metric scores.\n","    \"\"\"\n","    # model.eval()\n","    # for batch in generate_batch_sized_chunks(dataset, batch_size=batch_size):\n","    #     inputs = tokenizer([x[column_text] for x in batch],\n","    #                        max_length=1024,\n","    #                        truncation=True,\n","    #                        padding=\"max_length\",\n","    #                        return_tensors=\"pt\").to(device)\n","\n","    #     with torch.no_grad():\n","    #         summaries = model.generate(input_ids=inputs[\"input_ids\"],\n","    #                                    attention_mask=inputs[\"attention_mask\"],\n","    #                                    length_penalty=0.8,\n","    #                                    num_beams=8,\n","    #                                    max_length=128)\n","\n","    #     decoded_preds = tokenizer.batch_decode(summaries, skip_special_tokens=True)\n","    #     decoded_labels = [x[column_summary] for x in batch]\n","\n","    #     metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n","\n","    # return metric.compute()\n","    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n","    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n","\n","    for article_batch, target_batch in tqdm(\n","        zip(article_batches, target_batches), total=len(article_batches)):\n","\n","        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n","                        padding=\"max_length\", return_tensors=\"pt\")\n","\n","        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n","                            attention_mask=inputs[\"attention_mask\"].to(device),\n","                            length_penalty=0.8, num_beams=8, max_length=128)\n","        '''Parameter for length oenalty ensures that the model does not generate sequences that are too long.'''\n","\n","        # Finally, we decode the generated texts\n","        # replace the token, and add the decoded texts with the references to the metric.\n","        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n","                                clean_up_tokenization_spaces=True)\n","               for s in summaries]\n","\n","        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n","\n","\n","        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n","\n","    # Finally compute and return the ROUGE scores\n","    score = metric.compute()\n","    return score\n",""],"metadata":{"id":"nAWUEtqLtWRg","executionInfo":{"status":"ok","timestamp":1745648483776,"user_tz":-345,"elapsed":7,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ufPFNAUiuNPz","executionInfo":{"status":"ok","timestamp":1745648483785,"user_tz":-345,"elapsed":8,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Checking accuracy score for this pretrained model\n","rouge_metric = load_metric(\"rouge\")\n","score = calculate_metric_on_test_ds(dataset_samsung[\"test\"], rouge_metric, model_pegasus, tokenizer, batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOX5O0I2tHyc","executionInfo":{"status":"ok","timestamp":1745649674080,"user_tz":-345,"elapsed":14,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"669e9c92-e28e-4048-ca90-741a57b1fc03"},"execution_count":22,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [19:44<00:00,  2.89s/it]\n"]}]},{"cell_type":"code","source":["# List of ROUGE metric types we want to extract from the evaluation scores\n","rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n","\n","# Create a dictionary of {metric_name: score} using only the needed metrics\n","rouge_dict = {rn: score[rn] for rn in rouge_names}\n","\n","# Convert the dictionary into a one-row DataFrame for neat tabular display\n","# Useful for logging, plotting, or comparing different models\n","pd.DataFrame(rouge_dict, index=[\"pegasus\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"oyXBipjdtvPI","executionInfo":{"status":"ok","timestamp":1745650786289,"user_tz":-345,"elapsed":33,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"2cb2f259-be52-46df-bbb2-67adeb18700d"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           rouge1  rouge2    rougeL  rougeLsum\n","pegasus  0.015421  0.0003  0.015408   0.015412"],"text/html":["\n","  <div id=\"df-233c8cde-0d3d-4350-96e9-28987950c8d4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>rougeLsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pegasus</th>\n","      <td>0.015421</td>\n","      <td>0.0003</td>\n","      <td>0.015408</td>\n","      <td>0.015412</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-233c8cde-0d3d-4350-96e9-28987950c8d4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-233c8cde-0d3d-4350-96e9-28987950c8d4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-233c8cde-0d3d-4350-96e9-28987950c8d4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.01542095603647126,\n        \"max\": 0.01542095603647126,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.01542095603647126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0003002498707478649,\n        \"max\": 0.0003002498707478649,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0003002498707478649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.015408100008768846,\n        \"max\": 0.015408100008768846,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.015408100008768846\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLsum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.015411692708958563,\n        \"max\": 0.015411692708958563,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.015411692708958563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# Training with custom data"],"metadata":{"id":"R1C0AeXD4TBL","executionInfo":{"status":"ok","timestamp":1745650621443,"user_tz":-345,"elapsed":5,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["dataset_samsung"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7PpwLrc4pqd","executionInfo":{"status":"ok","timestamp":1745650660539,"user_tz":-345,"elapsed":24,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"477a9e15-a72d-4314-ab32-78c83a8e7c1b"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 14732\n","    })\n","    test: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 819\n","    })\n","    validation: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 818\n","    })\n","})"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# Tokenizing the data for model input\n","\n","def convert_examples_to_features(example_batch):\n","    \"\"\"\n","    Converts a batch of examples into input features usable by the model.\n","\n","    This includes:\n","    - Tokenizing the input text (dialogue) with a max length of 1024 tokens.\n","    - Tokenizing the target text (summary) separately with a shorter max length.\n","    - Creating attention masks and labels required for model training/inference.\n","\n","    Returns a dictionary containing:\n","    - input_ids: Tokenized input text\n","    - attention_mask: Indicates which tokens are actual input vs. padding\n","    - labels: Tokenized target summary (used for training loss or evaluation)\n","    \"\"\"\n","\n","    # Tokenize the input text (dialogue)\n","    input_encodings = tokenizer(example_batch['dialogue'], max_length=1024, truncation=True)\n","\n","    # Tokenize the target text (summary); this tells the tokenizer weâ€™re preparing labels\n","    with tokenizer.as_target_tokenizer():\n","        target_encodings = tokenizer(example_batch['summary'], max_length=128, truncation=True)\n","\n","    # Return all features needed for the model\n","    return {\n","        'input_ids': input_encodings['input_ids'],\n","        'attention_mask': input_encodings['attention_mask'],\n","        'labels': target_encodings['input_ids']\n","    }\n","\n","# Apply the tokenization function to the whole dataset using batching for speed\n","dataset_samsung_pt = dataset_samsung.map(convert_examples_to_features, batched=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["ebfd5ce61c994aaca1b97bc9aaab3715","247cd0120737437bbca487eed099abfd","0427acc3208c4469a0593567c7954a6b","4b4f5f7757ae412984c1c54185c4f9b4","cb6d3395334249b4a433605c41932458","b1e825ba38b94e3083b27334480e1101","e5c8466293d7493d839694605121b8a0","1eb79be7abd84d2eac3f543c8292a60a","d19f037f95bd4200ae4d7a2840a44b45","62a15031d318479c9271c39e41afa642","ef97c4d41c5349e8b7d7682d08c674c3","38a59841a3e548b8b56d94e7d31e5885","25dd78ad6d97412696c870faa3d8e8f3","4cb73342e1704f97a3f69f9643389328","c9215a0503ab44aba082243004d4a8a1","04c30feb23ce40b2b2911b9b6d831368","74073fada0da4004abd5f5eff598d484","233e53504ab9462ba37ba115e5a2e243","0bf0c169703446a8b3ec107080ea9517","e143c95a89514b80831f7e8ce7e24371","5deba76df330493487639d7eaeb30591","c26acb4c2e754a95bb7a8dd4e8cf4c3d","9c56d27e5be846deaabaf6a95e1d7929","73f29e457a1a4bb5b1e85c670ca5f6b0","77ba88d0963f4381926a683e0b601f42","7407436326424669b3804302f918e739","84bac9b8d9c1413cbaa89b672782da3a","7fface83d2d44595aefda99fe59810b4","d49b0e3eab834dde975170b43aea67c0","bf4e2c7523aa43a3bcdfd4dc01d53adb","b1cd103ae3944acfa8c4b45166416bca","bf54c726d7be4a99b3084b0de62650bb","21066ef183a4428a9fa71af4be9056d5"]},"id":"Stg5n1Rh4swV","executionInfo":{"status":"ok","timestamp":1745650839877,"user_tz":-345,"elapsed":15597,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"4e2b15ee-0d00-4ed2-e0d5-0dc4f50589fe"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebfd5ce61c994aaca1b97bc9aaab3715"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38a59841a3e548b8b56d94e7d31e5885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/818 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c56d27e5be846deaabaf6a95e1d7929"}},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"GbEJvi4A4tFj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_samsung_pt[\"train\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwyQBoC44tSa","executionInfo":{"status":"ok","timestamp":1745650840258,"user_tz":-345,"elapsed":12,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"6a0e1089-11d7-4e59-b5f8-41f9e28923e9"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '13818513',\n"," 'dialogue': \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n"," 'summary': 'Amanda baked cookies and will bring Jerry some tomorrow.',\n"," 'input_ids': [12195,\n","  151,\n","  125,\n","  7091,\n","  3659,\n","  107,\n","  842,\n","  119,\n","  245,\n","  181,\n","  152,\n","  10508,\n","  151,\n","  7435,\n","  147,\n","  12195,\n","  151,\n","  125,\n","  131,\n","  267,\n","  650,\n","  119,\n","  3469,\n","  29344,\n","  1],\n"," 'attention_mask': [1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1],\n"," 'labels': [12195, 7091, 3659, 111, 138, 650, 10508, 181, 3469, 107, 1]}"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":[],"metadata":{"id":"Ml5C12hl5eD1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the data collator used for preparing batches of data for sequence-to-sequence models\n","from transformers import DataCollatorForSeq2Seq\n","\n","# Create a data collator for the Pegasus model that:\n","# - Pads inputs and labels to the longest sequence in each batch\n","# - Ensures label padding is handled correctly for loss computation\n","# - Works seamlessly with the tokenizer and model\n","seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)\n"],"metadata":{"id":"7OjFMHZB5jTx","executionInfo":{"status":"ok","timestamp":1745650917307,"user_tz":-345,"elapsed":5,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3ECJJL9q5jXf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","\n","# Define the training configuration using Hugging Face's TrainingArguments\n","trainer_args = TrainingArguments(\n","    output_dir='pegasus-samsum',              # Directory to save model checkpoints and logs\n","    num_train_epochs=1,                       # Number of times the model sees the entire training dataset\n","    warmup_steps=500,                         # Number of steps for learning rate warm-up\n","    per_device_train_batch_size=1,            # Batch size per GPU/CPU for training\n","    per_device_eval_batch_size=1,             # Batch size per GPU/CPU for evaluation\n","    weight_decay=0.01,                        # Weight decay to reduce overfitting\n","    logging_steps=10,                         # Log training metrics every 10 steps\n","    gradient_accumulation_steps=16            # Accumulate gradients over 16 steps before performing an update\n","    # (This helps simulate a larger batch size without needing more memory)\n",")\n","\n","# Initialize the Trainer using:\n","trainer = Trainer(\n","    model=model_pegasus,\n","    args=trainer_args,\n","    tokenizer=tokenizer,\n","    data_collator=seq2seq_data_collator,\n","    train_dataset=dataset_samsung_pt[\"train\"],\n","    eval_dataset=dataset_samsung_pt[\"validation\"]\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5E-9c9Q5jaL","executionInfo":{"status":"ok","timestamp":1745651272455,"user_tz":-345,"elapsed":93,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"bd25267a-ab06-48cc-8825-52e218d9b561"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-36-e27713140244>:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Tv4EnRVu5jcZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"BBIckfe45jfO","executionInfo":{"status":"ok","timestamp":1745654232705,"user_tz":-345,"elapsed":579209,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"81dab61c-df46-458c-8975-3832cc659fbd"},"execution_count":37,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mniteshofficial876\u001b[0m (\u001b[33mniteshofficial876-pulchowk-campus\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.19.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250426_071057-o0dalfjz</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/niteshofficial876-pulchowk-campus/huggingface/runs/o0dalfjz' target=\"_blank\">pegasus-samsum</a></strong> to <a href='https://wandb.ai/niteshofficial876-pulchowk-campus/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/niteshofficial876-pulchowk-campus/huggingface' target=\"_blank\">https://wandb.ai/niteshofficial876-pulchowk-campus/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/niteshofficial876-pulchowk-campus/huggingface/runs/o0dalfjz' target=\"_blank\">https://wandb.ai/niteshofficial876-pulchowk-campus/huggingface/runs/o0dalfjz</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='741' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [741/920 37:20 < 09:02, 0.33 it/s, Epoch 0.80/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>3.217100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.993600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>3.108200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>3.021200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.675300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.690500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>2.725900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>2.526900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>2.375400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>2.508000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>2.297800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>2.261400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>2.103100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>2.148100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>2.209400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.976000</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>1.983400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.975300</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>1.837400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.945800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.918700</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>1.772100</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>1.853700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.767900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.857800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>1.801000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>1.774300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>1.738400</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>1.851400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.685700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>1.868600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>1.918700</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>1.818100</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>1.734500</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.744600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.643700</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>1.668200</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>1.706700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>1.684000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.707700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>1.711800</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.638600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>1.833600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>1.709200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.655800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>1.709300</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>1.686700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.638200</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>1.627000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.653300</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>1.655000</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>1.624300</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>1.680800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>1.559200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.671900</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>1.694300</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>1.716000</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>1.631400</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>1.547000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.679600</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>1.565200</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>1.636100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>1.640000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>1.613100</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.510500</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>1.539400</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>1.588000</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>1.583800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>1.566900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.630900</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>1.589000</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>1.565300</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>1.549700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [920/920 47:00, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>3.217100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.993600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>3.108200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>3.021200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.675300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.690500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>2.725900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>2.526900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>2.375400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>2.508000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>2.297800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>2.261400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>2.103100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>2.148100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>2.209400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.976000</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>1.983400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.975300</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>1.837400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.945800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.918700</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>1.772100</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>1.853700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.767900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.857800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>1.801000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>1.774300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>1.738400</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>1.851400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.685700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>1.868600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>1.918700</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>1.818100</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>1.734500</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.744600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.643700</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>1.668200</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>1.706700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>1.684000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.707700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>1.711800</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.638600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>1.833600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>1.709200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.655800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>1.709300</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>1.686700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.638200</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>1.627000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.653300</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>1.655000</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>1.624300</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>1.680800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>1.559200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.671900</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>1.694300</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>1.716000</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>1.631400</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>1.547000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.679600</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>1.565200</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>1.636100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>1.640000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>1.613100</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.510500</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>1.539400</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>1.588000</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>1.583800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>1.566900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.630900</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>1.589000</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>1.565300</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>1.549700</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>1.650800</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>1.566900</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>1.584800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>1.562700</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>1.553600</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>1.535000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.647800</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>1.542900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>1.615500</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>1.622900</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>1.521900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>1.544400</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>1.579300</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>1.603800</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>1.523500</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>1.552000</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.583800</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>1.523600</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>1.581800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=920, training_loss=1.8249299857927406, metrics={'train_runtime': 2941.1595, 'train_samples_per_second': 5.009, 'train_steps_per_second': 0.313, 'total_flos': 5528248038285312.0, 'train_loss': 1.8249299857927406, 'epoch': 0.9991854466467553})"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[],"metadata":{"id":"Oegc9O2A5jhH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Model trained successfully\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YwMQ9mU5jjl","executionInfo":{"status":"ok","timestamp":1745654560891,"user_tz":-345,"elapsed":21,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"6bcd131d-cee4-4acb-b699-6d8d4db6cbff"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Model trained successfully\n"]}]},{"cell_type":"code","source":["# ROUGE-1\tOverlap of unigrams (individual words) between the generated and reference summary.\n","# ROUGE-2\tOverlap of bigrams (two-word sequences).\n","# ROUGE-L\tLongest Common Subsequence (LCS) â€” how long the longest matching word sequence is.\n","# ROUGE-Lsum\tA version of ROUGE-L tailored for summarization across multiple sentences.\n","# Higher values = better summaries (closer to human-written ones)."],"metadata":{"id":"MycjMn3fPIoW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = calculate_metric_on_test_ds(\n","  dataset_samsung[\"test\"], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = \"dialogue\", column_summary= \"summary\"\n",")\n","\n","rouge_dict = {rn: score[rn] for rn in rouge_names}\n","\n","pd.DataFrame(rouge_dict, index = [\"pegasus\"] )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98},"id":"0tstYSpL5jl8","executionInfo":{"status":"ok","timestamp":1745656413992,"user_tz":-345,"elapsed":1684,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"016325c8-f97d-473a-9dc5-bb57ef65972e"},"execution_count":41,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [12:50<00:00,  1.88s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["           rouge1   rouge2    rougeL  rougeLsum\n","pegasus  0.018536  0.00033  0.018457   0.018493"],"text/html":["\n","  <div id=\"df-2a0cd612-542c-422d-b43f-040f2a659313\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>rougeLsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pegasus</th>\n","      <td>0.018536</td>\n","      <td>0.00033</td>\n","      <td>0.018457</td>\n","      <td>0.018493</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a0cd612-542c-422d-b43f-040f2a659313')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2a0cd612-542c-422d-b43f-040f2a659313 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2a0cd612-542c-422d-b43f-040f2a659313');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.018536381643582223,\n        \"max\": 0.018536381643582223,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018536381643582223\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.00032991424758673735,\n        \"max\": 0.00032991424758673735,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.00032991424758673735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.01845706275865301,\n        \"max\": 0.01845706275865301,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.01845706275865301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLsum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.01849313585036825,\n        \"max\": 0.01849313585036825,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.01849313585036825\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":[],"metadata":{"id":"nmYGUCOyH-BP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving the model\n","model_pegasus.save_pretrained(\"pegasus-samsum-model\")"],"metadata":{"id":"c0evBi-EH-j9","executionInfo":{"status":"ok","timestamp":1745656570526,"user_tz":-345,"elapsed":29369,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# saving the tokenizer\n","tokenizer.save_pretrained(\"tokenizer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0aRj0mwH-m9","executionInfo":{"status":"ok","timestamp":1745656571107,"user_tz":-345,"elapsed":136,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"328fe9af-5c99-42c6-f968-a87c2428f934"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('tokenizer/tokenizer_config.json',\n"," 'tokenizer/special_tokens_map.json',\n"," 'tokenizer/spiece.model',\n"," 'tokenizer/added_tokens.json',\n"," 'tokenizer/tokenizer.json')"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# Saving in drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzWXfJTcH-o-","executionInfo":{"status":"ok","timestamp":1745657653051,"user_tz":-345,"elapsed":48538,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"82bc7d3b-8ef0-4632-e666-c0b5067e9275"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Create the folder inside your Drive if it doesn't exist\n","!mkdir -p /content/drive/MyDrive/TextSummarizer\n","\n","# Move the model folder\n","!cp -r pegasus-samsum-model /content/drive/MyDrive/TextSummarizer/\n","\n","# Move the tokenizer folder\n","!cp -r tokenizer /content/drive/MyDrive/TextSummarizer/\n"],"metadata":{"id":"oewu4YuGH-rP","executionInfo":{"status":"ok","timestamp":1745657917417,"user_tz":-345,"elapsed":32746,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["# Inferencing using our trained model\n"],"metadata":{"id":"WSHTX2cLR357"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"OGvPUYYsH-ue","executionInfo":{"status":"ok","timestamp":1745657994440,"user_tz":-345,"elapsed":57,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"108b2778-48e9-4772-d42c-4f127e5dc0f0"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lH1AR0utSN5V","executionInfo":{"status":"ok","timestamp":1745657996461,"user_tz":-345,"elapsed":125,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"ffc4d94f-df7b-45fe-ab3a-59d0bbef70a1"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/           \u001b[01;34mpegasus-samsum-model\u001b[0m/  \u001b[01;34mtokenizer\u001b[0m/\n","\u001b[01;34mpegasus-samsum\u001b[0m/  \u001b[01;34msample_data\u001b[0m/           \u001b[01;34mwandb\u001b[0m/\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nU5_IhTOSOuw","executionInfo":{"status":"ok","timestamp":1745657361319,"user_tz":-345,"elapsed":122,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"07b8634b-e64f-4697-89b3-254570694cb5"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/           \u001b[01;34mpegasus-samsum-model\u001b[0m/  \u001b[01;34mtokenizer\u001b[0m/\n","\u001b[01;34mpegasus-samsum\u001b[0m/  \u001b[01;34msample_data\u001b[0m/           \u001b[01;34mwandb\u001b[0m/\n"]}]},{"cell_type":"code","source":["# Loading tokenizers\n","tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/TextSummarizer/tokenizer\")"],"metadata":{"id":"LT1fxoNdSXGT","executionInfo":{"status":"ok","timestamp":1745658319809,"user_tz":-345,"elapsed":400,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["dataset_samsung = load_dataset(\"samsum\")"],"metadata":{"id":"PYD2v2z9V19e","executionInfo":{"status":"ok","timestamp":1745658341964,"user_tz":-345,"elapsed":1306,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["sample_text = dataset_samsung[\"test\"][0][\"dialogue\"]\n","\n","reference = dataset_samsung[\"test\"][0][\"summary\"]"],"metadata":{"id":"udeXY4lbV1_0","executionInfo":{"status":"ok","timestamp":1745658365666,"user_tz":-345,"elapsed":5,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["sample_text, reference"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1SN4wDHfV2CO","executionInfo":{"status":"ok","timestamp":1745658377739,"user_tz":-345,"elapsed":26,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"4d913c08-3049-48d5-d71c-4a641f2035f1"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(\"Hannah: Hey, do you have Betty's number?\\nAmanda: Lemme check\\nHannah: <file_gif>\\nAmanda: Sorry, can't find it.\\nAmanda: Ask Larry\\nAmanda: He called her last time we were at the park together\\nHannah: I don't know him well\\nHannah: <file_gif>\\nAmanda: Don't be shy, he's very nice\\nHannah: If you say so..\\nHannah: I'd rather you texted him\\nAmanda: Just text him ðŸ™‚\\nHannah: Urgh.. Alright\\nHannah: Bye\\nAmanda: Bye bye\",\n"," \"Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\")"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["# Define the generation parameters for the summarization process.\n","gen_kwargs = {\n","    \"length_penalty\": 0.8,  # Controls the length of the generated summary. Lower values favor shorter summaries.\n","    \"num_beams\": 8,         # Defines the number of beams used for beam search (a search strategy during generation).\n","    \"max_length\": 128       # Maximum length of the generated summary. Limits the length of the output.\n","}\n","\n","# Create a summarization pipeline using the fine-tuned Pegasus model.\n","# This pipeline will automatically handle tokenization, model inference, and decoding.\n","pipe = pipeline(\n","    \"summarization\",       # Task type is summarization.\n","    model=\"pegasus-samsum-model\",  # The model that was fine-tuned and saved earlier.\n","    tokenizer=tokenizer    # The tokenizer to convert input text into tokens and decode the output.\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"j7l9YAvVV2Eg","executionInfo":{"status":"ok","timestamp":1745658471847,"user_tz":-345,"elapsed":8890,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"353a0440-cf5c-4187-c6f6-17621da2c6a0"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}]},{"cell_type":"code","source":["# Dialogue and summary from the dataset\n","\n","print(\"Dialogue:\")\n","print(sample_text)\n","\n","\n","print(\"\\nReference Summary:\")\n","print(reference)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dja3hXiPV2Gw","executionInfo":{"status":"ok","timestamp":1745658582593,"user_tz":-345,"elapsed":38,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"09d5d254-eb9a-49d8-f7f3-f1d809278b27"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Dialogue:\n","Hannah: Hey, do you have Betty's number?\n","Amanda: Lemme check\n","Hannah: <file_gif>\n","Amanda: Sorry, can't find it.\n","Amanda: Ask Larry\n","Amanda: He called her last time we were at the park together\n","Hannah: I don't know him well\n","Hannah: <file_gif>\n","Amanda: Don't be shy, he's very nice\n","Hannah: If you say so..\n","Hannah: I'd rather you texted him\n","Amanda: Just text him ðŸ™‚\n","Hannah: Urgh.. Alright\n","Hannah: Bye\n","Amanda: Bye bye\n","\n","Reference Summary:\n","Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PJCBfEfLV2Kf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model Prediction from our fine tuned model\n","print(\"\\nModel Summary:\")\n","print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFEwnJ9HW4lT","executionInfo":{"status":"ok","timestamp":1745658607781,"user_tz":-345,"elapsed":962,"user":{"displayName":"NITESH BANIYA","userId":"14298799394837654304"}},"outputId":"e1c285ef-b498-4665-fab0-176538babc3f"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stderr","text":["Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Model Summary:\n","Amanda can't find Betty's number. Larry called Betty last time they were at the park together. Hannah wants Amanda to text Larry. Amanda will text Larry.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5lzvG44DW4nZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N9KrZpEKW4pd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UhK_pjg2W4rj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v3C1pxlGW4th"},"execution_count":null,"outputs":[]}]}